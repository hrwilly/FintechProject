{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4db7be1-a3b7-43c3-81c6-70899f1aa21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e33ad7b2-dae1-4d5f-9d8f-4a8053f6a508",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"ticker_data_augmented_2019start.pkl\", \"rb\") as file:\n",
    "    loaded_data = pickle.load(file)\n",
    "\n",
    "all_stocks = list(loaded_data.keys())[:-1]\n",
    "all_stocks.remove('BG')\n",
    "all_stocks.remove('ROST')\n",
    "all_stocks.remove('AMCR')\n",
    "all_stocks.remove('STE')\n",
    "\n",
    "\n",
    "'''\n",
    "all_stocks.remove('ABNB')\n",
    "all_stocks.remove('CEG')\n",
    "all_stocks.remove('GEHC')\n",
    "all_stocks.remove('GEV')\n",
    "all_stocks.remove('KVUE')\n",
    "all_stocks.remove('PLTR')\n",
    "all_stocks.remove('SOLV')\n",
    "all_stocks.remove('SW')\n",
    "all_stocks.remove('VLTO')'''\n",
    "\n",
    "loaded_data = {stock : pl.DataFrame(loaded_data[stock].reset_index()).with_columns((pl.col('Annualized Vol') / np.sqrt(252)).alias('Daily Vol')) for stock in all_stocks + ['SPY']}\n",
    "\n",
    "mkt_weight = vol_weight = 0.5\n",
    "std_weight = downside_weight = 0.5\n",
    "volfac_weight = dividend_weight1 = 0.5\n",
    "de_weight = eps_weight = roe_weight = 0.333333333333333333333\n",
    "ep_weight = bv_weight = dividend_weight2 = 0.333333333333333333333\n",
    "qual_weight = alpha_weight1 = val_weight = 0.333333333333333333333\n",
    "pe_weight = pbv_weight = 0.5\n",
    "growth_weight = alpha_weight2 = 0.5\n",
    "beta_weight = alpha_weight3 = mom_weight = 0.333333333333333333333\n",
    "\n",
    "final_ports = {'Date' : [], 'low' : [], 'moderate' : [], 'high' : [], 'very_high' : []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53265db0-ce66-4bb5-a975-21ba7d688489",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(data, stocks, factor):\n",
    "    \n",
    "    values = [data[stock][factor].mean() for stock in stocks if factor in data[stock] and not np.isnan(data[stock][factor].mean())]\n",
    "    \n",
    "    if len(values) == 0 or max(values) == min(values):\n",
    "        return {stock: 0 for stock in stocks}\n",
    "    \n",
    "    min_val = min(values)\n",
    "    max_val = max(values)\n",
    "    \n",
    "    return {stock: (data[stock][factor].mean() - min_val) / (max_val - min_val)\n",
    "            if factor in data[stock] and not np.isnan(data[stock][factor].mean()) else 0\n",
    "            for stock in stocks}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b134ade5-3b08-44cc-95dd-4cd85fe7048f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def screening_level_1(data, stocks):\n",
    "\n",
    "    mkt_cap = normalize(data, stocks, 'Market_Cap')\n",
    "    daily_vol = normalize(data, stocks, 'Daily Vol')\n",
    "\n",
    "    score = {}\n",
    "\n",
    "    for stock in stocks:\n",
    "        score[stock] = -mkt_cap[stock] * mkt_weight + daily_vol[stock] * vol_weight\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2a6fb39-e1fb-4483-a25a-410755780ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def screening_level_2(data, stocks):\n",
    "\n",
    "    low_metrics = low_calcs(data, stocks[1])\n",
    "    med_metrics = med_calcs(data, stocks[2])\n",
    "    high_metrics = high_calcs(data, stocks[3])\n",
    "    vhigh_metrics = vhigh_calcs(data, stocks[4])\n",
    "\n",
    "    sorted_low = sorted(low_metrics.items(), key=lambda x: x[1])\n",
    "    top_low = len(sorted_low) // 2\n",
    "    low_ports = list(dict(sorted_low[:top_low]).keys())\n",
    "\n",
    "    sorted_med = sorted(med_metrics.items(), key=lambda x: x[1])\n",
    "    top_med = len(sorted_med) // 2\n",
    "    med_ports = list(dict(sorted_med[:top_med]).keys())\n",
    "\n",
    "    high_ports = [key for key, value in high_metrics.items() if value == 0]\n",
    "\n",
    "    vhigh_ports = [key for key, value in vhigh_metrics.items() if value == 0]\n",
    "\n",
    "    return  low_ports, med_ports, high_ports, vhigh_ports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56e74951-d916-4680-babd-7df55cecc44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def low_calcs(data, stocks):\n",
    "\n",
    "    std = {}\n",
    "    downside = {}\n",
    "    dividend_yield = dividend_metric(data, stocks)\n",
    "\n",
    "    for stock in stocks:\n",
    "        std[stock] = pl.DataFrame({'std' : data[stock].std()['Return'] * np.sqrt(252)})\n",
    "        downside[stock] = pl.DataFrame({'downside' : np.sqrt((np.minimum(0, data[stock]['Return'])**2).mean())})\n",
    "\n",
    "    std_norm = normalize(std, stocks, 'std')\n",
    "    downside_norm = normalize(downside, stocks, 'downside')\n",
    "    dividend_norm = normalize(dividend_yield, stocks, 'dividend')\n",
    "\n",
    "    score = {}\n",
    "\n",
    "    for stock in stocks:\n",
    "        vol_score = std_weight * std_norm[stock] + downside_weight * downside_norm[stock]\n",
    "        score[stock] = vol_score * volfac_weight + dividend_norm[stock] * dividend_weight1\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a9c4585-a064-41d7-a5da-932d2fc42cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def med_calcs(data, stocks):\n",
    "\n",
    "    alpha = alpha_metric(data, stocks)\n",
    "    alpha_norm = normalize(alpha, stocks, 'alpha')\n",
    "\n",
    "    roe = {}\n",
    "    debt_equity = {}\n",
    "    eps_growth_vol = {}\n",
    "    earnings_price = {}\n",
    "    book_val_price = {}\n",
    "    dividend_yield = dividend_metric(data, stocks)\n",
    "\n",
    "    for stock in stocks:\n",
    "        debt_equity[stock] = pl.DataFrame({'D/E' : data[stock]['Debt_Ratio'].mean()})\n",
    "        \n",
    "        g = (data[stock]['EPS'] - data[stock]['EPS'].shift(1)) / data[stock]['EPS'].shift(1)\n",
    "        eps_growth_vol[stock] = pl.DataFrame({'EPS' : np.sqrt(((g - g.mean())**2).mean())})\n",
    "\n",
    "        shares_outstanding = data[stock]['Market_Cap'] / data[stock]['Adj Close']\n",
    "        net_income = shares_outstanding * data[stock]['EPS']\n",
    "        roe[stock] = pl.DataFrame({'ROE' : net_income / data[stock]['Book_Value']})\n",
    "\n",
    "        earnings_price[stock] = pl.DataFrame({'EP' : (data[stock]['EPS'] / data[stock]['Adj Close']).mean()})\n",
    "    \n",
    "        book_val_per_share = data[stock]['Book_Value'] / shares_outstanding\n",
    "        book_val_price[stock] = pl.DataFrame({'BV' : (book_val_per_share / data[stock]['Adj Close']).mean()})\n",
    "\n",
    "    #for stock in stocks:\n",
    "    #    print(stock + ': ' + str(roe[stock]['ROE'].mean()))\n",
    "    de_norm = normalize(debt_equity, stocks, 'D/E')\n",
    "    eps_norm = normalize(eps_growth_vol, stocks, 'EPS')\n",
    "    roe_norm = normalize(roe, stocks, 'ROE')\n",
    "\n",
    "    ep_norm = normalize(earnings_price, stocks, 'EP')\n",
    "    bv_norm = normalize(earnings_price, stocks, 'BV')\n",
    "    dividend_norm = normalize(dividend_yield, stocks, 'dividend')\n",
    "\n",
    "    score = {}\n",
    "\n",
    "    for stock in stocks:\n",
    "        qual_score = de_weight * de_norm[stock] + eps_weight * eps_norm[stock] + roe_weight * roe_norm[stock]\n",
    "        val_score = ep_weight * ep_norm[stock] + bv_weight * bv_norm[stock] + dividend_weight2 * dividend_norm[stock]\n",
    "        score[stock] = qual_score * qual_weight + alpha_norm[stock] * alpha_weight1 + val_score * val_weight\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d891c2ef-667c-4043-b4a0-5bf9b450cc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def high_calcs(data, stocks):\n",
    "\n",
    "    alpha = alpha_metric(data, stocks)\n",
    "    alpha_norm = normalize(alpha, stocks, 'alpha')\n",
    "\n",
    "    pe = {}\n",
    "    pbv = {}\n",
    "\n",
    "    for stock in stocks:\n",
    "\n",
    "        price_earnings = 1 / (data[stock]['EPS'] / data[stock]['Adj Close']).mean()\n",
    "        pe[stock] = pl.DataFrame({'PE' : price_earnings})\n",
    "\n",
    "        shares_outstanding = data[stock]['Market_Cap'] / data[stock]['Adj Close']\n",
    "        book_val_per_share = data[stock]['Book_Value'] / shares_outstanding\n",
    "        price_book = 1 / (book_val_per_share / data[stock]['Adj Close']).mean()\n",
    "        pbv[stock] = pl.DataFrame({'PBV' : price_book})\n",
    "\n",
    "    sorted_pe = sorted(pe.items(), key=lambda x: x[1]['PE'][0], reverse=True)\n",
    "    top_pe = len(sorted_pe) // 2\n",
    "    pe_score1 = dict(sorted_pe[:top_pe]).keys()\n",
    "    pe = {stock_check: pl.DataFrame({'PE' : 0 if stock_check not in pe_score1 else 1}) for stock_check in stocks}\n",
    "    pe_norm = normalize(pe, pe, 'PE')\n",
    "\n",
    "    sorted_pbv = sorted(pbv.items(), key=lambda x: x[1]['PBV'][0], reverse=True)\n",
    "    top_pbv = len(sorted_pbv) // 2\n",
    "    pbv_score1 = dict(sorted_pbv[:top_pbv]).keys()\n",
    "    pbv = {stock_check: pl.DataFrame({'PBV' : 0 if stock_check not in pbv_score1 else 1}) for stock_check in stocks}\n",
    "    pbv_norm = normalize(pbv, pbv, 'PBV')\n",
    "\n",
    "    score = {}\n",
    "    \n",
    "    for stock in stocks:\n",
    "        growth_score = pe_weight * pe_norm[stock] + pbv_weight * pbv_norm[stock]\n",
    "        score[stock] = growth_score * growth_weight + alpha_norm[stock] * alpha_weight2\n",
    "\n",
    "    return score\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ec09ac4-285c-4fa2-a8ce-c27aaeb08ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vhigh_calcs(data, stocks):\n",
    "\n",
    "    alpha = alpha_metric(data, stocks)\n",
    "    alpha_norm = normalize(alpha, stocks, 'alpha')\n",
    "\n",
    "    beta = {}\n",
    "    mom = {}\n",
    "    \n",
    "    for stock in stocks:\n",
    "    \n",
    "        cov = np.cov(data[stock]['Return'].dropna(), data['SPY']['Return'].dropna().tail(len(data[stock]['Return'].dropna())))\n",
    "        var = loaded_data['SPY']['Return'].var()\n",
    "        beta[stock] = pl.DataFrame({'beta' : 1 if cov[1][0] / var > 1 else 0})\n",
    "        #print(stock)\n",
    "        momentum = data[stock].tail(1)['Adj Close'] - data[stock]['Adj Close'][0]\n",
    "        mom[stock] = pl.DataFrame({'momentum' : 0 if momentum.iloc[-1] > 0 else 1})\n",
    "\n",
    "    beta_norm = normalize(beta, stocks, 'beta')\n",
    "    mom_norm = normalize(mom, stocks, 'momentum')\n",
    "\n",
    "    score = {}\n",
    "\n",
    "    for stock in stocks:\n",
    "        score[stock] = alpha_weight3 * alpha_norm[stock] + beta_weight * beta_norm[stock] + mom_weight * mom_norm[stock]\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "72c6855d-2b25-4402-8cfd-d36ea94ee030",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dividend_metric(data, stocks):\n",
    "\n",
    "    dividend_yield = {}\n",
    "\n",
    "    for stock in stocks:\n",
    "        dividend_yield[stock] = pl.DataFrame({'dividend' : (data[stock]['Last_Dividend'] / data[stock]['Adj Close']).mean() * 4})\n",
    "\n",
    "    return dividend_yield\n",
    "\n",
    "\n",
    "def alpha_metric(data, stocks):\n",
    "\n",
    "    alpha = {}\n",
    "\n",
    "    for stock in stocks:\n",
    "\n",
    "        val = np.max((data[stock]['Return'] - data['SPY']['Return']).mean(), 0)\n",
    "        alpha[stock] = pl.DataFrame({'alpha' : 1 if val == 0 else 0})\n",
    "\n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1cbb5a6c-92bd-4229-befa-cb95f6f55bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_to_risk(score, stocks):\n",
    "\n",
    "    measure_vals = list(score.values())\n",
    "    measure_vals = [x for x in measure_vals if not np.isnan(x)]\n",
    "    quartiles = {\n",
    "        'Q' : [1, 2, 3, 4],\n",
    "        'Measure' : [np.quantile(measure_vals, x) for x in [0.25, 0.5, 0.75, 1.0]]\n",
    "    }\n",
    "\n",
    "    quart = pd.DataFrame(quartiles).set_index('Q')\n",
    "\n",
    "    risk_levels = {}\n",
    "\n",
    "    for stock in stocks:\n",
    "        for i, threshold in enumerate(quart['Measure'], start=1):\n",
    "            if score[stock] <= threshold:\n",
    "                risk_levels[stock] = i\n",
    "                break\n",
    "        else: risk_levels[stock] = np.nan\n",
    "\n",
    "    return risk_levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "387ce653-584b-416e-99cd-b4fc7872ad20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def risk_groups(data, stocks):\n",
    "\n",
    "    level1_scores = screening_level_1(data, stocks)\n",
    "    level1_cats = score_to_risk(level1_scores, stocks)\n",
    "\n",
    "    ports_level1 = {1: [], 2: [], 3: [], 4: []}\n",
    "\n",
    "\n",
    "    for stock in stocks:\n",
    "        for j in ports_level1.keys():\n",
    "            if level1_cats[stock] == j:\n",
    "                ports_level1[j].append(stock)\n",
    "                break\n",
    "\n",
    "    #print(len(ports_level1[1]))\n",
    "    #print(len(ports_level1[1]))\n",
    "    #print(len(ports_level1[1]))\n",
    "    #print(len(ports_level1[1]))\n",
    "\n",
    "    low_ports, med_ports, high_ports, vhigh_ports = screening_level_2(data, ports_level1)\n",
    "\n",
    "    #print(len(low_ports))\n",
    "    #print(len(med_ports))\n",
    "    #print(len(high_ports))\n",
    "    #print(len(vhigh_ports))\n",
    "\n",
    "    final_ports['Date'].append(data['SPY']['Date'].iloc[-1])\n",
    "    final_ports['low'].append(low_ports)\n",
    "    final_ports['moderate'].append(med_ports)\n",
    "    final_ports['high'].append(high_ports)\n",
    "    final_ports['very_high'].append(vhigh_ports)\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "21cb219a-0602-4242-9779-e422fbd05e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date, timedelta\n",
    "\n",
    "# Generate a list of quarter start dates from 2021 to 2024\n",
    "start_year = 2019\n",
    "end_year = 2025\n",
    "dates = []\n",
    "\n",
    "for year in range(start_year, end_year + 1):\n",
    "    for month in [1, 4, 7, 10]:  # Quarter start months: January, April, July, October\n",
    "        dates.append(date(year, month, 1))\n",
    "\n",
    "dates.remove(date(2025, 4, 1))\n",
    "dates.remove(date(2025, 7, 1))\n",
    "dates.remove(date(2025, 10, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "deddddb4-bd32-426d-8fe0-8d721807805a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-01-01\n",
      "2019-04-01\n",
      "2019-07-01\n",
      "2019-10-01\n",
      "2020-01-01\n",
      "2020-04-01\n",
      "2020-07-01\n",
      "2020-10-01\n",
      "2021-01-01\n",
      "2021-04-01\n",
      "2021-07-01\n",
      "2021-10-01\n",
      "2022-01-01\n",
      "2022-04-01\n",
      "2022-07-01\n",
      "2022-10-01\n",
      "2023-01-01\n",
      "2023-04-01\n",
      "2023-07-01\n",
      "2023-10-01\n",
      "2024-01-01\n",
      "2024-04-01\n",
      "2024-07-01\n",
      "2024-10-01\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, len(dates)):\n",
    "    data = {}\n",
    "    for stock in all_stocks + ['SPY']:\n",
    "        data[stock] = loaded_data[stock].filter(pl.col('Date').is_between(dates[i - 1], dates[i] - timedelta(days = 1))).to_pandas()\n",
    "    print(dates[i - 1])\n",
    "    risk_groups(data, all_stocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "26548e8e-917d-44c0-ae56-60c09d7fea8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(final_ports).set_index('Date').to_excel('Portfolios_start2020.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "b6ef6c12-d1a5-41b0-9d6c-9548ac5fff3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1_493, 13)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Date</th><th>Adj Close</th><th>Close</th><th>High</th><th>Low</th><th>Open</th><th>Volume</th><th>Last_Dividend</th><th>Return</th><th>Log_Return</th><th>Rolling Std_252</th><th>Annualized Vol</th><th>Daily Vol</th></tr><tr><td>datetime[ns]</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>i64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>2019-01-02 00:00:00</td><td>228.403625</td><td>250.179993</td><td>251.210007</td><td>245.949997</td><td>245.979996</td><td>126925200</td><td>1.435</td><td>0.00104</td><td>0.00104</td><td>0.010711</td><td>0.170032</td><td>0.010711</td></tr><tr><td>2019-01-03 00:00:00</td><td>222.953278</td><td>244.210007</td><td>248.570007</td><td>243.669998</td><td>248.229996</td><td>144140700</td><td>1.435</td><td>-0.023863</td><td>-0.024152</td><td>0.010805</td><td>0.171522</td><td>0.010805</td></tr><tr><td>2019-01-04 00:00:00</td><td>230.421249</td><td>252.389999</td><td>253.110001</td><td>247.169998</td><td>247.589996</td><td>142628800</td><td>1.435</td><td>0.033496</td><td>0.032947</td><td>0.011004</td><td>0.17469</td><td>0.011004</td></tr><tr><td>2019-01-07 00:00:00</td><td>232.238068</td><td>254.380005</td><td>255.949997</td><td>251.690002</td><td>252.690002</td><td>103139100</td><td>1.435</td><td>0.007885</td><td>0.007854</td><td>0.011013</td><td>0.17482</td><td>0.011013</td></tr><tr><td>2019-01-08 00:00:00</td><td>234.420013</td><td>256.769989</td><td>257.309998</td><td>254.0</td><td>256.820007</td><td>102512600</td><td>1.435</td><td>0.009395</td><td>0.009351</td><td>0.011021</td><td>0.174948</td><td>0.011021</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>2024-11-29 00:00:00</td><td>602.549988</td><td>602.549988</td><td>603.349976</td><td>599.380005</td><td>599.659973</td><td>30177400</td><td>1.746</td><td>0.006212</td><td>0.006193</td><td>0.007659</td><td>0.121584</td><td>0.007659</td></tr><tr><td>2024-12-02 00:00:00</td><td>603.630005</td><td>603.630005</td><td>604.320007</td><td>602.469971</td><td>602.969971</td><td>31746000</td><td>1.746</td><td>0.001792</td><td>0.001791</td><td>0.007657</td><td>0.121555</td><td>0.007657</td></tr><tr><td>2024-12-03 00:00:00</td><td>603.909973</td><td>603.909973</td><td>604.159973</td><td>602.340027</td><td>603.390015</td><td>26906600</td><td>1.746</td><td>0.000464</td><td>0.000464</td><td>0.007652</td><td>0.121464</td><td>0.007652</td></tr><tr><td>2024-12-04 00:00:00</td><td>607.659973</td><td>607.659973</td><td>607.909973</td><td>604.950012</td><td>605.630005</td><td>42648700</td><td>1.746</td><td>0.00621</td><td>0.00619</td><td>0.007647</td><td>0.121396</td><td>0.007647</td></tr><tr><td>2024-12-05 00:00:00</td><td>607.359985</td><td>607.359985</td><td>608.190002</td><td>606.804993</td><td>607.659973</td><td>7345928</td><td>1.746</td><td>-0.000494</td><td>-0.000494</td><td>0.007647</td><td>0.1214</td><td>0.007647</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1_493, 13)\n",
       "┌──────────────────────┬────────────┬────────────┬────────────┬───┬────────────┬──────────┬────────────────┬───────────┐\n",
       "│ Date                 ┆ Adj Close  ┆ Close      ┆ High       ┆ … ┆ Log_Return ┆ Rolling  ┆ Annualized Vol ┆ Daily Vol │\n",
       "│ ---                  ┆ ---        ┆ ---        ┆ ---        ┆   ┆ ---        ┆ Std_252  ┆ ---            ┆ ---       │\n",
       "│ datetime[ns]         ┆ f64        ┆ f64        ┆ f64        ┆   ┆ f64        ┆ ---      ┆ f64            ┆ f64       │\n",
       "│                      ┆            ┆            ┆            ┆   ┆            ┆ f64      ┆                ┆           │\n",
       "╞══════════════════════╪════════════╪════════════╪════════════╪═══╪════════════╪══════════╪════════════════╪═══════════╡\n",
       "│ 2019-01-02 00:00:00  ┆ 228.403625 ┆ 250.179993 ┆ 251.210007 ┆ … ┆ 0.00104    ┆ 0.010711 ┆ 0.170032       ┆ 0.010711  │\n",
       "│ 2019-01-03 00:00:00  ┆ 222.953278 ┆ 244.210007 ┆ 248.570007 ┆ … ┆ -0.024152  ┆ 0.010805 ┆ 0.171522       ┆ 0.010805  │\n",
       "│ 2019-01-04 00:00:00  ┆ 230.421249 ┆ 252.389999 ┆ 253.110001 ┆ … ┆ 0.032947   ┆ 0.011004 ┆ 0.17469        ┆ 0.011004  │\n",
       "│ 2019-01-07 00:00:00  ┆ 232.238068 ┆ 254.380005 ┆ 255.949997 ┆ … ┆ 0.007854   ┆ 0.011013 ┆ 0.17482        ┆ 0.011013  │\n",
       "│ 2019-01-08 00:00:00  ┆ 234.420013 ┆ 256.769989 ┆ 257.309998 ┆ … ┆ 0.009351   ┆ 0.011021 ┆ 0.174948       ┆ 0.011021  │\n",
       "│ …                    ┆ …          ┆ …          ┆ …          ┆ … ┆ …          ┆ …        ┆ …              ┆ …         │\n",
       "│ 2024-11-29 00:00:00  ┆ 602.549988 ┆ 602.549988 ┆ 603.349976 ┆ … ┆ 0.006193   ┆ 0.007659 ┆ 0.121584       ┆ 0.007659  │\n",
       "│ 2024-12-02 00:00:00  ┆ 603.630005 ┆ 603.630005 ┆ 604.320007 ┆ … ┆ 0.001791   ┆ 0.007657 ┆ 0.121555       ┆ 0.007657  │\n",
       "│ 2024-12-03 00:00:00  ┆ 603.909973 ┆ 603.909973 ┆ 604.159973 ┆ … ┆ 0.000464   ┆ 0.007652 ┆ 0.121464       ┆ 0.007652  │\n",
       "│ 2024-12-04 00:00:00  ┆ 607.659973 ┆ 607.659973 ┆ 607.909973 ┆ … ┆ 0.00619    ┆ 0.007647 ┆ 0.121396       ┆ 0.007647  │\n",
       "│ 2024-12-05 00:00:00  ┆ 607.359985 ┆ 607.359985 ┆ 608.190002 ┆ … ┆ -0.000494  ┆ 0.007647 ┆ 0.1214         ┆ 0.007647  │\n",
       "└──────────────────────┴────────────┴────────────┴────────────┴───┴────────────┴──────────┴────────────────┴───────────┘"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_data['SPY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c940be-158d-46b9-8ff6-bcc6dcd64201",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
